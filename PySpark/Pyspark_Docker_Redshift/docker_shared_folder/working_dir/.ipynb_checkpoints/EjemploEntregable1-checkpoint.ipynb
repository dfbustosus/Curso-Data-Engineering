{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9d8ad5-0ba7-4f10-bbc4-963a950c85fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ejemplo Entregable 1\n",
    "\n",
    "Pasos del ejemplo:\n",
    "* Bajar datos de una API en formato JSON\n",
    "* Cargar datos en la tabla de Redshift\n",
    "\n",
    "Esto lo vamos a llevar a cabo usando `requests`, `Spark` y un driver de conexión de `Postgres`\n",
    "\n",
    "![Imagen](./entregable_arquitectura.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ee5997-74e0-4ae9-a586-d36e2b3776be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1) Bajar datos de una API en formato JSON\n",
    "\n",
    "Para este ejemplo vamos a usar la API de [Datos Argentina](https://www.datos.gob.ar/)\n",
    "\n",
    "Y nos vamos a traer los datos de: Exportaciones de cereales. En millones de dólares FOB\n",
    "\n",
    "Para probar la API ir a: [API de Series de Tiempo AR: Generador de URLs](https://datosgobar.github.io/series-tiempo-ar-call-generator/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b8041f0-c750-42c3-8943-515cd0131743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "\n",
    "def get_api_call(ids, **kwargs):\n",
    "    API_BASE_URL = \"https://apis.datos.gob.ar/series/api/\"\n",
    "    kwargs[\"ids\"] = \",\".join(ids)\n",
    "    return \"{}{}?{}\".format(API_BASE_URL, \"series\", urllib.parse.urlencode(kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697c682c-f3f5-4662-8a63-cd33cd34444b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://apis.datos.gob.ar/series/api/series?start_date=2020-01-01&ids=75.3_IEC_0_M_26\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo: https://apis.datos.gob.ar/series/api/series?ids=75.3_IEC_0_M_26&start_date=2020-01-01\n",
    "api_call = get_api_call([\"75.3_IEC_0_M_26\"], start_date=\"2020-01-01\")\n",
    "print(api_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b04e992-36f2-4e9b-9a9a-bc417426f700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [['2020-01-01', 1158.0], ['2020-02-01', 762.0], ['2020-03-01', 947.0], ['2020-04-01', 943.0], ['2020-05-01', 788.0], ['2020-06-01', 845.0], ['2020-07-01', 806.0], ['2020-08-01', 862.0], ['2020-09-01', 605.0], ['2020-10-01', 529.0], ['2020-11-01', 358.0], ['2020-12-01', 404.0], ['2021-01-01', 773.0], ['2021-02-01', 682.0], ['2021-03-01', 1041.0], ['2021-04-01', 1211.0], ['2021-05-01', 1074.0], ['2021-06-01', 1303.0], ['2021-07-01', 1447.0], ['2021-08-01', 1411.0], ['2021-09-01', 1312.0], ['2021-10-01', 1194.0], ['2021-11-01', 880.0], ['2021-12-01', 1329.0], ['2022-01-01', 1528.0], ['2022-02-01', 1415.0], ['2022-03-01', 1642.0], ['2022-04-01', 1837.0], ['2022-05-01', 1567.0], ['2022-06-01', 1403.0], ['2022-07-01', 1680.0], ['2022-08-01', 1321.0], ['2022-09-01', 957.0], ['2022-10-01', 727.0], ['2022-11-01', 650.0], ['2022-12-01', 887.0], ['2023-01-01', 740.0], ['2023-02-01', 712.0], ['2023-03-01', 952.0], ['2023-04-01', 678.0], ['2023-05-01', 650.0], ['2023-06-01', 840.0], ['2023-07-01', 963.0], ['2023-08-01', 1001.0]], 'count': 44, 'meta': [{'frequency': 'month', 'start_date': '2020-01-01', 'end_date': '2023-08-01'}, {'catalog': {'title': 'Datos Programación Macroeconómica'}, 'dataset': {'title': 'Exportaciones FOB por rubro', 'description': 'Intercambio Comercial Argentino en millones de dólares', 'issued': '2017-09-28', 'source': 'Instituto Nacional de Estadística y Censos (INDEC)'}, 'distribution': {'title': 'Exportaciones. Valores mensuales', 'downloadURL': 'https://infra.datos.gob.ar/catalog/sspm/dataset/75/distribution/75.3/download/exportaciones-mensual.csv'}, 'field': {'description': 'Exportaciones de cereales. En millones de dólares FOB', 'id': '75.3_IEC_0_M_26', 'units': 'Millones de dólares', 'representation_mode': 'value', 'representation_mode_units': 'Millones de dólares'}}], 'params': {'start_date': '2020-01-01', 'ids': '75.3_IEC_0_M_26', 'identifiers': [{'id': '75.3_IEC_0_M_26', 'distribution': '75.3', 'dataset': '75'}]}}\n"
     ]
    }
   ],
   "source": [
    "result = requests.get(api_call).json()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d78ac-50eb-4385-80bb-4478be1240d3",
   "metadata": {},
   "source": [
    "## 2) Cargar datos en la tabla de Redshift\n",
    "\n",
    "La tabla debe estar creada en el schema que esté usando. El create table es el siguiente:\n",
    "\n",
    "```SQL\n",
    "create table if not exists lucas_trubiano_coderhouse.exportaciones_cereales (\n",
    "    date_from VARCHAR(10) distkey,\n",
    "    millones_dolares decimal(10,2),\n",
    "    frequency varchar(12)\n",
    ") sortkey(date_from);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c4ae6a-6d33-48c5-bc76-78280bc5bb80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.9\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "784bd8a8-1f06-4eed-b011-8c6b04b6f5df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear sesion de Spark\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, lit, col\n",
    "\n",
    "# Postgres and Redshift JDBCs\n",
    "driver_path = \"/home/coder/working_dir/driver_jdbc/postgresql-42.2.27.jre7.jar\"\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = f'--driver-class-path {driver_path} --jars {driver_path} pyspark-shell'\n",
    "os.environ['SPARK_CLASSPATH'] = driver_path\n",
    "\n",
    "# Create SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"Conexion entre Pyspark y Redshift\") \\\n",
    "        .config(\"spark.jars\", driver_path) \\\n",
    "        .config(\"spark.executor.extraClassPath\", driver_path) \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f82b7ea8-81ee-4a17-83e5-0b7a85542b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5cd853-7e96-4ca9-b4e5-38e2d8da9395",
   "metadata": {},
   "source": [
    "Revisar documentación:\n",
    "* [AWS Redshift + Spark documentation](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-redshift.html)\n",
    "* [Spark + Redshift connector](https://github.com/spark-redshift-community/spark-redshift#readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6c9313b-f55d-41b6-b0b3-2028781bb352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to Redshift using psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    host=env['AWS_REDSHIFT_HOST'],\n",
    "    port=env['AWS_REDSHIFT_PORT'],\n",
    "    dbname=env['AWS_REDSHIFT_DBNAME'],\n",
    "    user=env['AWS_REDSHIFT_USER'],\n",
    "    password=env['AWS_REDSHIFT_PASSWORD']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f4ae99-28b8-4deb-8efe-536a4fc924e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created!\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(f\"\"\"\n",
    "create table if not exists {env['AWS_REDSHIFT_SCHEMA']}.exportaciones_cereales (\n",
    "    date_from VARCHAR(10) distkey,\n",
    "    millones_dolares decimal(10,2),\n",
    "    frequency varchar(12)\n",
    ") sortkey(date_from);\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "print(\"Table created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4fe5a1d-769a-4e42-975c-2391f27326cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agents, agentsx, bo, calls, callsx, cl, contact_persons, cpi, currencyrate, customer_data, customers, customersx, data_clima_sem7, ec, eventos_apocalipticos, exportaciones_cereales, fraude, fraude2, interest_over_time, mining_data, nba_stats_david, pe, politicas_2050, prediccion_fin_mundo, predicted_end_of_world, product, project_feedbacks, py, us, uy, ve, zips\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(f\"\"\"\n",
    "SELECT\n",
    "  distinct tablename\n",
    "FROM\n",
    "  PG_TABLE_DEF\n",
    "WHERE\n",
    "  schemaname = '{env['AWS_REDSHIFT_SCHEMA']}';\n",
    "\"\"\")\n",
    "# resultado = cursor.fetchall()\n",
    "print(\", \".join(map(lambda x: x[0], cursor.fetchall())))\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5426b03c-0298-4331-a242-9d4c2b55bf5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the DataFrame with the specified column names\n",
    "df = spark.createDataFrame(result['data'], [\"date_from\", \"millones_dolares\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e65938a-dd85-476a-b8d5-44e33227a8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_from: string (nullable = true)\n",
      " |-- millones_dolares: double (nullable = true)\n",
      "\n",
      "+----------+----------------+\n",
      "| date_from|millones_dolares|\n",
      "+----------+----------------+\n",
      "|2020-01-01|          1158.0|\n",
      "|2020-02-01|           762.0|\n",
      "|2020-03-01|           947.0|\n",
      "|2020-04-01|           943.0|\n",
      "|2020-05-01|           788.0|\n",
      "|2020-06-01|           845.0|\n",
      "|2020-07-01|           806.0|\n",
      "|2020-08-01|           862.0|\n",
      "|2020-09-01|           605.0|\n",
      "|2020-10-01|           529.0|\n",
      "|2020-11-01|           358.0|\n",
      "|2020-12-01|           404.0|\n",
      "|2021-01-01|           773.0|\n",
      "|2021-02-01|           682.0|\n",
      "|2021-03-01|          1041.0|\n",
      "|2021-04-01|          1211.0|\n",
      "|2021-05-01|          1074.0|\n",
      "|2021-06-01|          1303.0|\n",
      "|2021-07-01|          1447.0|\n",
      "|2021-08-01|          1411.0|\n",
      "+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6987abc0-1927-466c-aaea-79493449dcb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_from: string (nullable = true)\n",
      " |-- millones_dolares: double (nullable = true)\n",
      " |-- frequency: string (nullable = false)\n",
      "\n",
      "+----------+----------------+---------+\n",
      "| date_from|millones_dolares|frequency|\n",
      "+----------+----------------+---------+\n",
      "|2020-01-01|          1158.0|  Mensual|\n",
      "|2020-02-01|           762.0|  Mensual|\n",
      "|2020-03-01|           947.0|  Mensual|\n",
      "|2020-04-01|           943.0|  Mensual|\n",
      "|2020-05-01|           788.0|  Mensual|\n",
      "|2020-06-01|           845.0|  Mensual|\n",
      "|2020-07-01|           806.0|  Mensual|\n",
      "|2020-08-01|           862.0|  Mensual|\n",
      "|2020-09-01|           605.0|  Mensual|\n",
      "|2020-10-01|           529.0|  Mensual|\n",
      "|2020-11-01|           358.0|  Mensual|\n",
      "|2020-12-01|           404.0|  Mensual|\n",
      "|2021-01-01|           773.0|  Mensual|\n",
      "|2021-02-01|           682.0|  Mensual|\n",
      "|2021-03-01|          1041.0|  Mensual|\n",
      "|2021-04-01|          1211.0|  Mensual|\n",
      "|2021-05-01|          1074.0|  Mensual|\n",
      "|2021-06-01|          1303.0|  Mensual|\n",
      "|2021-07-01|          1447.0|  Mensual|\n",
      "|2021-08-01|          1411.0|  Mensual|\n",
      "+----------+----------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_to_write = df.withColumn('frequency', lit('Mensual'))\n",
    "df_to_write.printSchema()\n",
    "df_to_write.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "846c31de-8995-45de-87ff-9f573852e8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_to_write.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", f\"jdbc:postgresql://{env['AWS_REDSHIFT_HOST']}:{env['AWS_REDSHIFT_PORT']}/{env['AWS_REDSHIFT_DBNAME']}\") \\\n",
    "    .option(\"dbtable\", f\"{env['AWS_REDSHIFT_SCHEMA']}.exportaciones_cereales\") \\\n",
    "    .option(\"user\", env['AWS_REDSHIFT_USER']) \\\n",
    "    .option(\"password\", env['AWS_REDSHIFT_PASSWORD']) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e42cca47-336f-4870-a528-b1c56d7c64b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query Redshift using Spark SQL\n",
    "query = f\"select * from {env['AWS_REDSHIFT_SCHEMA']}.exportaciones_cereales\"\n",
    "data = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", f\"jdbc:postgresql://{env['AWS_REDSHIFT_HOST']}:{env['AWS_REDSHIFT_PORT']}/{env['AWS_REDSHIFT_DBNAME']}\") \\\n",
    "    .option(\"dbtable\", f\"({query}) as tmp_table\") \\\n",
    "    .option(\"user\", env['AWS_REDSHIFT_USER']) \\\n",
    "    .option(\"password\", env['AWS_REDSHIFT_PASSWORD']) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f23e27db-346e-4905-8848-8179409a9139",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_from: string (nullable = true)\n",
      " |-- millones_dolares: double (nullable = true)\n",
      " |-- frequency: string (nullable = true)\n",
      "\n",
      "+----------+----------------+---------+\n",
      "| date_from|millones_dolares|frequency|\n",
      "+----------+----------------+---------+\n",
      "|2020-01-01|          1158.0|  Mensual|\n",
      "|2020-02-01|           762.0|  Mensual|\n",
      "|2020-03-01|           947.0|  Mensual|\n",
      "|2020-04-01|           943.0|  Mensual|\n",
      "|2020-05-01|           788.0|  Mensual|\n",
      "|2020-06-01|           845.0|  Mensual|\n",
      "|2020-07-01|           806.0|  Mensual|\n",
      "|2020-08-01|           862.0|  Mensual|\n",
      "|2020-09-01|           605.0|  Mensual|\n",
      "|2020-10-01|           529.0|  Mensual|\n",
      "|2020-11-01|           358.0|  Mensual|\n",
      "|2020-12-01|           404.0|  Mensual|\n",
      "|2021-01-01|           773.0|  Mensual|\n",
      "|2021-02-01|           682.0|  Mensual|\n",
      "|2021-03-01|          1041.0|  Mensual|\n",
      "|2021-04-01|          1211.0|  Mensual|\n",
      "|2021-05-01|          1074.0|  Mensual|\n",
      "|2021-06-01|          1303.0|  Mensual|\n",
      "|2021-07-01|          1447.0|  Mensual|\n",
      "|2021-08-01|          1411.0|  Mensual|\n",
      "+----------+----------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "311a75ef-818b-4b8d-9f48-43e62ca2f806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e0b31e-28c2-4135-9f37-6375e20f61ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
